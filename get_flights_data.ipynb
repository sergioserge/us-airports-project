{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to download flights csv file from transtats website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook, we will**\n",
    "1. Download a csv file for your chosen year(s) and month(s)\n",
    "2. Prepare the data for further processing\n",
    "3. Push the prepared data to a table in the database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import requests #package for getting data from the web\n",
    "from zipfile import * #package for unzipping zip files\n",
    "from sql import get_engine #adjust this as necessary to match your sql.py connection methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download csv file with flight data for your specific year/month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, you are going to download a csv file containing flight data from [this website](https://transtats.bts.gov).    \n",
    "You can specify, which data you want to download. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a month/year that you want to explore further.\n",
    "With the following command lines, you will download a csv file on public flight data from [this website](https://transtats.bts.gov) containing data of your chosen month/year.    \n",
    "The file will be stored in a data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies path for saving file\n",
    "data_path ='data1/' \n",
    "# Create the data folder\n",
    "!mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2010] # list of years you want to look at, specify one year\n",
    "months = [9] # list of months you want to look at, specify one month\n",
    "# Here: September 2018\n",
    "\n",
    "# Loop through months\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        # Get the file from the website https://transtats.bts.gov\n",
    "        zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "        csv_file = f'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv'\n",
    "        url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "        # Download the database\n",
    "        r = requests.get(f'{url}', verify=False)\n",
    "        # Save database to local file storage\n",
    "        with open(data_path+zip_file, 'wb') as f:\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip your file\n",
    "with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your data\n",
    "df = pd.read_csv(path+csv_file, low_memory = False)\n",
    "display(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare the csv file for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we clean and prepare our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Since the dataset consists of a lot of columns, we we define which ones to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up your database connection\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns in the DB have different naming as in the source csv files. Lets get the names from the DB\n",
    "table_name_sql = '''SELECT COLUMN_NAME \n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_NAME = 'flights'\n",
    "                    AND TABLE_SCHEMA ='public'\n",
    "                    ORDER BY ordinal_position'''\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can clean up the results into a clean list\n",
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case the above fails here are the results\n",
    "new_column_names_alternate = ['flight_date', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', \n",
    "                'arr_delay', 'airline', 'tail_number', 'flight_number', 'origin', 'dest', 'air_time', 'distance', 'cancelled', 'diverted' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) With the next function, we make our csv file ready to be uploaded to SQL.  \n",
    "We only keep to above specified columns and convert the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function and check resulting dataframe\n",
    "df_clean = clean_airline_df(df)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you decide to only look at specific airports, it is a good decision to filter for them in advance.  \n",
    "This function does the filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the airports you are interested in and put them as a list in the function.\n",
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering airline df for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function, filtering for New York area airports\n",
    "airports=['JFK', 'LGA', 'EWR']\n",
    "if len(airports) > 0:\n",
    "    df_selected_airports = select_airport(df_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_clean\n",
    "    \n",
    "df_selected_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Push the prepared data to a table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "# Example: flights_sp for Sina's flights table\n",
    "table_name = 'test_ae'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This will take a minute or two...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_selected_airports.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_selected_airports.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a709bd14b92f3497c9bd81ca413d4ca4704d27f10583fff57ac89f5e8b281e63"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('sql-practice': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
